{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aec9wVIGGOAm"
      },
      "outputs": [],
      "source": [
        "words = open('names.txt', 'r').read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBUfwYnRGOAp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1v46X03cGOAt"
      },
      "outputs": [],
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEG9jYaeGOAx"
      },
      "outputs": [],
      "source": [
        "# --------- !!! OPTIMIZATION !!! yay --------------\n",
        "\"\"\"\n",
        "DATA recorded --\n",
        "\n",
        "will keep iterations to 100, so it doesn't overfit to the data, and andrej kept it to 100 :)\n",
        "\n",
        "1. 2.098693370819092, -35, 100 iterations \n",
        "\n",
        "2. 2.0668435096740723 = -40 rate, 100 iterations\n",
        "\n",
        "3. NOISE lowest - 2.0696253776550293 , final = 2.075587034225464 = -45 rate, 100 iterations\n",
        "   - early stopping could work!?\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-Wk4VdFGOAy"
      },
      "outputs": [],
      "source": [
        "# --------- !!! NETWORK :DD !!! --------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAkSmRJsGOAy",
        "outputId": "003aa99d-d20e-4440-fd46-8101a858bc04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of examples:  260179\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# create the dataset\n",
        "\n",
        "xs, ys = [], []\n",
        "for w in words:\n",
        "\n",
        "  # here we add 2 '.' to construct the trigram dataset, could there be a better way? \n",
        "  chs = ['.'] + ['.'] + list(w) + ['.'] + ['.']\n",
        "\n",
        "  # we zip 3 arrays (trigram)\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    ix3 = stoi[ch3]\n",
        "    xs.append((ix1, ix2))\n",
        "    ys.append(ix3)\n",
        "\n",
        "num = len(xs)\n",
        "print('number of examples: ', num)    \n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "# initialize the 'network'\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "# 54 inputs to 27 neurons , 54 because we give one hot encodings for 2 27 inputs. \n",
        "W = torch.randn((54, 27), generator=g, requires_grad=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zdv34qp9GOAy",
        "outputId": "fc47ae1d-2ded-47ef-ff4b-b7ce26365710",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.080402135848999\n",
            "2.071906089782715\n",
            "2.071983575820923\n",
            "2.0700387954711914\n",
            "2.0700981616973877\n",
            "2.069244623184204\n",
            "2.0692801475524902\n",
            "2.068802833557129\n",
            "2.068819046020508\n",
            "2.0685172080993652\n",
            "2.0685200691223145\n",
            "2.06831431388855\n",
            "2.0683085918426514\n",
            "2.0681610107421875\n",
            "2.0681498050689697\n",
            "2.068040132522583\n",
            "2.068026065826416\n",
            "2.067941904067993\n",
            "2.0679264068603516\n",
            "2.0678598880767822\n",
            "2.0678439140319824\n",
            "2.0677907466888428\n",
            "2.0677738189697266\n",
            "2.06773042678833\n",
            "2.067713737487793\n",
            "2.0676774978637695\n",
            "2.0676610469818115\n",
            "2.0676302909851074\n",
            "2.067615032196045\n",
            "2.0675880908966064\n",
            "2.067572832107544\n",
            "2.067549228668213\n",
            "2.067534923553467\n",
            "2.067513942718506\n",
            "2.0674996376037598\n",
            "2.067481279373169\n",
            "2.067467451095581\n",
            "2.0674500465393066\n",
            "2.067436933517456\n",
            "2.0674214363098145\n",
            "2.067408561706543\n",
            "2.0673940181732178\n",
            "2.0673818588256836\n",
            "2.0673675537109375\n",
            "2.0673561096191406\n",
            "2.06734299659729\n",
            "2.067331314086914\n",
            "2.06731915473938\n",
            "2.067307710647583\n",
            "2.067295789718628\n",
            "2.0672848224639893\n",
            "2.0672731399536133\n",
            "2.067262649536133\n",
            "2.067251205444336\n",
            "2.0672411918640137\n",
            "2.067230701446533\n",
            "2.0672202110290527\n",
            "2.0672097206115723\n",
            "2.067199468612671\n",
            "2.0671894550323486\n",
            "2.0671794414520264\n",
            "2.067169427871704\n",
            "2.06715989112854\n",
            "2.0671498775482178\n",
            "2.067140579223633\n",
            "2.0671308040618896\n",
            "2.0671215057373047\n",
            "2.0671119689941406\n",
            "2.067103147506714\n",
            "2.06709361076355\n",
            "2.067084312438965\n",
            "2.067075252532959\n",
            "2.0670664310455322\n",
            "2.0670573711395264\n",
            "2.0670483112335205\n",
            "2.067039728164673\n",
            "2.067030668258667\n",
            "2.0670225620269775\n",
            "2.0670132637023926\n",
            "2.067004919052124\n",
            "2.0669965744018555\n",
            "2.066987991333008\n",
            "2.06697940826416\n",
            "2.0669713020324707\n",
            "2.066962718963623\n",
            "2.0669546127319336\n",
            "2.066946268081665\n",
            "2.0669379234313965\n",
            "2.066930055618286\n",
            "2.0669219493865967\n",
            "2.0669138431549072\n",
            "2.066905975341797\n",
            "2.0668978691101074\n",
            "2.066890001296997\n",
            "2.066882371902466\n",
            "2.0668742656707764\n",
            "2.066866636276245\n",
            "2.066859006881714\n",
            "2.0668511390686035\n",
            "2.0668435096740723\n"
          ]
        }
      ],
      "source": [
        "# gradient descent\n",
        "for k in range(100):\n",
        "  \n",
        "  # forward pass\n",
        "\n",
        "  xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
        "\n",
        "  # converting inputs to a 54 array\n",
        "  xenc = xenc.view(-1, 54)\n",
        "  \n",
        "  logits = xenc @ W # predict log-counts\n",
        "  counts = logits.exp() # counts, equivalent to N\n",
        "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
        "  print(loss.item())\n",
        "  \n",
        "  # backward pass\n",
        "  W.grad = None # set to zero the gradient\n",
        "  loss.backward()\n",
        "  \n",
        "  # update (found 35 to be better)\n",
        "  W.data += -40 * W.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJFu5LZgGOAz",
        "outputId": "ee57a476-8a17-46f2-e16b-5378a6e2d066",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mor.\n",
            "ays.\n",
            "minaymnnyaes.\n",
            "konamaloe.\n",
            "caonawiry.\n",
            "rie.\n",
            "oi.\n",
            "ondalaek.\n",
            "shalekirierielah.\n",
            "yshi.\n",
            "ga.\n",
            "ta.\n",
            "celyn.\n",
            "ilan.\n",
            "lullia.\n",
            "mikh.\n",
            "ai.\n",
            "fa.\n",
            "jilhel.\n",
            "aynni.\n",
            "leillquvaizacrevina.\n",
            "lanoynaysin.\n",
            "deneliasooseelolettefforyunni.\n",
            "ssimacay.\n",
            "hann.\n",
            "jaleemencilele.\n",
            "kialy.\n",
            "eryis.\n",
            "zaelefi.\n",
            "kayvionguslisar.\n",
            "tarlcamorejeylleni.\n",
            "din.\n",
            "embraandigarach.\n",
            "rie.\n",
            "dreis.\n",
            "jor.\n",
            "jon.\n",
            "ezyainn.\n",
            "jassana.\n",
            "ria.\n",
            "kadarlon.\n",
            "ch.\n",
            "aimartdigandes.\n",
            "ryan.\n",
            "siah.\n",
            "ivanvei.\n",
            "cana.\n",
            "lis.\n",
            "ou.\n",
            "biysinil.\n",
            "eve.\n",
            "blahire.\n",
            "tovila.\n",
            "ka.\n",
            "ka.\n",
            "kyemeloreah.\n",
            "obran.\n",
            "erelezio.\n",
            "allyoni.\n",
            "rielie.\n",
            "tra.\n",
            "iazlinbelannithll.\n",
            "haven.\n",
            "jez.\n",
            "gana.\n",
            "besh.\n",
            "ga.\n",
            "ta.\n",
            "shellevorlyeshisteely.\n",
            "rrastaraliah.\n",
            "bolei.\n",
            "kelai.\n",
            "marro.\n",
            "avis.\n",
            "jalan.\n",
            "mmiuh.\n",
            "riyatana.\n",
            "jerietolingen.\n",
            "bri.\n",
            "rsilen.\n",
            "randekkaes.\n",
            "vililon.\n",
            "lit.\n",
            "belio.\n",
            "zriossok.\n",
            "sellia.\n",
            "cer.\n",
            "ee.\n",
            "do.\n",
            "sun.\n",
            "emcrinsayant.\n",
            "an.\n",
            "iretano.\n",
            "sitan.\n",
            "urlos.\n",
            "lai.\n",
            "rany.\n",
            "ryelleyl.\n",
            "kyahandyl.\n",
            "xicalin.\n"
          ]
        }
      ],
      "source": [
        "# finally, sample from the 'neural net' model\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for i in range(100):\n",
        "  \n",
        "  out = []\n",
        "  #initial indexed, both 0 and 0\n",
        "  ix2 = [0, 0]\n",
        "\n",
        "  while True:\n",
        "    xenc = torch.zeros(1, 54)\n",
        "    xenc[0][ix2[0]] = 1\n",
        "\n",
        "    #we add 27 here, because it's a 54 input array, and the second index has to go to the next 1-27 array\n",
        "    xenc[0][ix2[1] + 27] = 1\n",
        "\n",
        "    logits = xenc @ W # predict log-counts\n",
        "    counts = logits.exp() # counts, equivalent to N\n",
        "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "    # ----------\n",
        "    \n",
        "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    ix = ix\n",
        "\n",
        "    #we swap the inputs, to make them the inputs for the next character\n",
        "    ix2[0] = ix2[1]\n",
        "    ix2[1] = ix\n",
        "\n",
        "    out.append(itos[ix])\n",
        "    if ix == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oo45MlDJGOAz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}